{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import pickle\n",
    "import deeplabcut\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the 3D DeepLabCut project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the base path for each different 3D project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = r'D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing 3d project\n"
     ]
    }
   ],
   "source": [
    "config_path_3d = os.path.join(base_path, 'config.yaml')\n",
    "\n",
    "if os.path.exists(config_path_3d):\n",
    "    print('Found existing 3d project')\n",
    "else:\n",
    "    print('Create new 3d project!')\n",
    "    deeplabcut.create_new_project_3d('UpAndDown','Ming', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you edit the 3D config.yaml file. The cameras should be named 'rear' and 'lateral', and the config file paths for the 2D tracking should be updated correctly. Also update the skeleton to match the 2D tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do the calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/DeepLabCut/DeepLabCut/blob/master/docs/Overviewof3D.md for an overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the code below is modified from the DLC repository here: https://github.com/DeepLabCut/DeepLabCut/blob/master/deeplabcut/pose_estimation_3d/camera_calibration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of internal corners on our checkboard. (e.g., 8x8 squares has 7x7 internal corners)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbrow = 7\n",
    "cbcol = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_names = ['rear', 'lateral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "framedir = os.path.join(base_path, 'calibration_images')\n",
    "cornerdir = os.path.join(base_path, 'corners')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\calibration_images\\\\rear-006.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\calibration_images\\\\rear-007.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\calibration_images\\\\rear-008.jpg']\n",
      " ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\calibration_images\\\\lateral-006.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\calibration_images\\\\lateral-007.jpg'\n",
      "  'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\calibration_images\\\\lateral-008.jpg']]\n"
     ]
    }
   ],
   "source": [
    "filenames = []\n",
    "for cam1 in cam_names:\n",
    "    fn1 = glob.glob(os.path.join(framedir, cam1 + '*.jpg'))\n",
    "    fn1.sort()\n",
    "    filenames.append(fn1)\n",
    "\n",
    "filenames = np.array(filenames)\n",
    "\n",
    "print(filenames[:,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotategrid = [False, True]\n",
    "mirror = [False, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Termination criteria\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((cbrow * cbcol, 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:cbcol, 0:cbrow].T.reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rear-006\n",
      "Found!\n",
      "rear-007\n",
      "Found!\n",
      "rear-008\n",
      "Found!\n",
      "rear-009\n",
      "Found!\n",
      "rear-010\n",
      "Found!\n",
      "rear-011\n",
      "Found!\n",
      "rear-012\n",
      "Found!\n",
      "rear-013\n",
      "Found!\n",
      "rear-014\n",
      "Found!\n",
      "rear-016\n",
      "Found!\n",
      "rear-017\n",
      "Found!\n",
      "rear-018\n",
      "Found!\n",
      "rear-019\n",
      "Found!\n",
      "rear-020\n",
      "Found!\n",
      "rear-021\n",
      "Found!\n",
      "rear-022\n",
      "Found!\n",
      "rear-023\n",
      "Found!\n",
      "lateral-006\n",
      "Found!\n",
      "lateral-007\n",
      "Found!\n",
      "lateral-008\n",
      "Found!\n",
      "lateral-009\n",
      "Found!\n",
      "lateral-010\n",
      "Found!\n",
      "lateral-011\n",
      "Found!\n",
      "lateral-012\n",
      "Found!\n",
      "lateral-013\n",
      "Found!\n",
      "lateral-014\n",
      "Found!\n",
      "lateral-016\n",
      "Found!\n",
      "lateral-017\n",
      "Found!\n",
      "lateral-018\n",
      "Found!\n",
      "lateral-019\n",
      "Found!\n",
      "lateral-020\n",
      "Found!\n",
      "lateral-021\n",
      "Found!\n",
      "lateral-022\n",
      "Found!\n",
      "lateral-023\n",
      "Found!\n"
     ]
    }
   ],
   "source": [
    "img_shape = {}\n",
    "objpoints = {}  # 3d point in real world space\n",
    "imgpoints = {}  # 2d points in image plane.\n",
    "dist_pickle = {}\n",
    "stereo_params = {}\n",
    "for cam in cam_names:\n",
    "    objpoints.setdefault(cam, [])\n",
    "    imgpoints.setdefault(cam, [])\n",
    "    dist_pickle.setdefault(cam, [])\n",
    "\n",
    "for cam, camfiles1, rot1, mirror1 in zip(cam_names, filenames, rotategrid, mirror):\n",
    "    for fn1 in camfiles1:\n",
    "        img = cv2.imread(fn1)\n",
    "        if mirror1:\n",
    "            img = cv2.flip(img, 1)  # flip horizontally\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "        pn, fn = os.path.split(fn1)\n",
    "        fn, ext = os.path.splitext(fn)\n",
    "\n",
    "        print('{}'.format(fn))\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (cbrow,cbcol), cv2.CALIB_CB_ADAPTIVE_THRESH + \\\n",
    "            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "\n",
    "        if ret:\n",
    "            print('Found!')\n",
    "            if rot1:\n",
    "                corners = corners.reshape((cbrow,cbcol, -1))\n",
    "                corners = corners.transpose((1, 0, 2))\n",
    "                corners = corners.reshape((cbrow*cbcol, 1, -1))\n",
    "            \n",
    "            img_shape[cam] = gray.shape[::-1]\n",
    "            objpoints[cam].append(objp)\n",
    "            corners = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "            imgpoints[cam].append(corners)            \n",
    "        else:\n",
    "            print('Not found')\n",
    "\n",
    "        img = cv2.drawChessboardCorners(img, (cbrow,cbcol), corners, ret)\n",
    "\n",
    "        cv2.imwrite(os.path.join(cornerdir, fn + '_corner.jpg'), img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_camera_matrix = os.path.join(base_path,'camera_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving intrinsic camera calibration matrices for rear as a pickle file in D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\camera_matrix\n",
      "Mean re-projection error for rear images: 0.189 pixels \n",
      "Saving intrinsic camera calibration matrices for lateral as a pickle file in D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\camera_matrix\n",
      "Mean re-projection error for lateral images: 0.181 pixels \n"
     ]
    }
   ],
   "source": [
    "for cam in cam_names:\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(\n",
    "        objpoints[cam], imgpoints[cam], img_shape[cam], None, None\n",
    "    )\n",
    "\n",
    "    # Save the camera calibration result for later use (we won't use rvecs / tvecs)\n",
    "    dist_pickle[cam] = {\n",
    "        \"mtx\": mtx,\n",
    "        \"dist\": dist,\n",
    "        \"objpoints\": objpoints[cam],\n",
    "        \"imgpoints\": imgpoints[cam],\n",
    "    }\n",
    "    pickle.dump(\n",
    "        dist_pickle,\n",
    "        open(\n",
    "            os.path.join(path_camera_matrix, cam + \"_intrinsic_params.pickle\"),\n",
    "            \"wb\",\n",
    "        ),\n",
    "    )\n",
    "    print(\n",
    "        \"Saving intrinsic camera calibration matrices for %s as a pickle file in %s\"\n",
    "        % (cam, os.path.join(path_camera_matrix))\n",
    "    )\n",
    "\n",
    "    # Compute mean re-projection errors for individual cameras\n",
    "    mean_error = 0\n",
    "    for i in range(len(objpoints[cam])):\n",
    "        imgpoints_proj, _ = cv2.projectPoints(\n",
    "            objpoints[cam][i], rvecs[i], tvecs[i], mtx, dist\n",
    "        )\n",
    "        error = cv2.norm(imgpoints[cam][i], imgpoints_proj, cv2.NORM_L2) / len(\n",
    "            imgpoints_proj\n",
    "        )\n",
    "        mean_error += error\n",
    "    print(\n",
    "        \"Mean re-projection error for %s images: %.3f pixels \"\n",
    "        % (cam, mean_error / len(objpoints[cam]))\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, w = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing stereo calibration for \n",
      "Saving the stereo parameters for every pair of cameras as a pickle file in D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\camera_matrix\n",
      "Camera calibration done! Use the function ``check_undistortion`` to check the check the calibration\n"
     ]
    }
   ],
   "source": [
    "# Compute stereo calibration for each pair of cameras\n",
    "camera_pair = [[cam_names[0], cam_names[1]]]\n",
    "for pair in camera_pair:\n",
    "    print(\"Computing stereo calibration for \" % pair)\n",
    "    (\n",
    "        retval,\n",
    "        cameraMatrix1,\n",
    "        distCoeffs1,\n",
    "        cameraMatrix2,\n",
    "        distCoeffs2,\n",
    "        R,\n",
    "        T,\n",
    "        E,\n",
    "        F,\n",
    "    ) = cv2.stereoCalibrate(\n",
    "        objpoints[pair[0]],\n",
    "        imgpoints[pair[0]],\n",
    "        imgpoints[pair[1]],\n",
    "        dist_pickle[pair[0]][\"mtx\"],\n",
    "        dist_pickle[pair[0]][\"dist\"],\n",
    "        dist_pickle[pair[1]][\"mtx\"],\n",
    "        dist_pickle[pair[1]][\"dist\"],\n",
    "        (h, w),\n",
    "        flags=cv2.CALIB_FIX_INTRINSIC,\n",
    "    )\n",
    "\n",
    "    # Stereo Rectification\n",
    "    rectify_scale = alpha  # Free scaling parameter check this https://docs.opencv.org/2.4/modules/calib3d/doc/camera_calibration_and_3d_reconstruction.html#fisheye-stereorectify\n",
    "    R1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(\n",
    "        cameraMatrix1,\n",
    "        distCoeffs1,\n",
    "        cameraMatrix2,\n",
    "        distCoeffs2,\n",
    "        (h, w),\n",
    "        R,\n",
    "        T,\n",
    "        alpha=rectify_scale,\n",
    "    )\n",
    "\n",
    "    stereo_params[pair[0] + \"-\" + pair[1]] = {\n",
    "        \"cameraMatrix1\": cameraMatrix1,\n",
    "        \"cameraMatrix2\": cameraMatrix2,\n",
    "        \"distCoeffs1\": distCoeffs1,\n",
    "        \"distCoeffs2\": distCoeffs2,\n",
    "        \"R\": R,\n",
    "        \"T\": T,\n",
    "        \"E\": E,\n",
    "        \"F\": F,\n",
    "        \"R1\": R1,\n",
    "        \"R2\": R2,\n",
    "        \"P1\": P1,\n",
    "        \"P2\": P2,\n",
    "        \"roi1\": roi1,\n",
    "        \"roi2\": roi2,\n",
    "        \"Q\": Q,\n",
    "        \"image_shape\": [img_shape[pair[0]], img_shape[pair[1]]],\n",
    "    }\n",
    "\n",
    "print(\n",
    "    \"Saving the stereo parameters for every pair of cameras as a pickle file in %s\"\n",
    "    % str(os.path.join(path_camera_matrix))\n",
    ")\n",
    "\n",
    "deeplabcut.auxiliaryfunctions.write_pickle(\n",
    "    os.path.join(path_camera_matrix, \"stereo_params.pickle\"), stereo_params\n",
    ")\n",
    "print(\n",
    "    \"Camera calibration done! Use the function ``check_undistortion`` to check the check the calibration\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.08822638e+03, 0.00000000e+00, 1.26291971e+03],\n",
       "       [0.00000000e+00, 5.37273202e+03, 5.51275139e+02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cameraMatrix2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check undistortion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't work, but the triangulation does. Just skip to the triangulation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images are undistorted and stored in D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\undistortion\n",
      "Use the function ``triangulate`` to undistort the dataframes and compute the triangulation\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_undistortion(config_path_3d, cbrow=cbrow, cbcol=cbcol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera_pair = [[cam_names[0], cam_names[1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_undistort = os.path.join(base_path, 'undistortion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairname = camera_pair[0][0] + \"-\" + camera_pair[0][1]\n",
    "map2_x, map2_y = cv2.initUndistortRectifyMap(\n",
    "    stereo_params[pairname][\"cameraMatrix2\"],\n",
    "    stereo_params[pairname][\"distCoeffs2\"],\n",
    "    stereo_params[pairname][\"R2\"],\n",
    "    stereo_params[pairname][\"P2\"],\n",
    "    (stereo_params[pairname][\"image_shape\"][1]),\n",
    "    cv2.CV_16SC2,\n",
    ")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       [[ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       [[ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        [ 32767,  32767],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       [[ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]],\n",
       "\n",
       "       [[ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        [ 32767, -32768],\n",
       "        ...,\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768],\n",
       "        [-32768, -32768]]], dtype=int16)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map2_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\TYTELL~1\\AppData\\Local\\Temp/ipykernel_17764/2808552771.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mgray1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 _, corners1 = cv2.findChessboardCorners(gray1, (cbcol, cbrow),  cv2.CALIB_CB_ADAPTIVE_THRESH + \\\n\u001b[0m\u001b[0;32m     28\u001b[0m             cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for pair in camera_pair:\n",
    "        map1_x, map1_y = cv2.initUndistortRectifyMap(\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"cameraMatrix1\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"distCoeffs1\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"R1\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"P1\"],\n",
    "            (stereo_params[pair[0] + \"-\" + pair[1]][\"image_shape\"][0]),\n",
    "            cv2.CV_16SC2,\n",
    "        )\n",
    "        map2_x, map2_y = cv2.initUndistortRectifyMap(\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"cameraMatrix2\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"distCoeffs2\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"R2\"],\n",
    "            stereo_params[pair[0] + \"-\" + pair[1]][\"P2\"],\n",
    "            (stereo_params[pair[0] + \"-\" + pair[1]][\"image_shape\"][1]),\n",
    "            cv2.CV_16SC2,\n",
    "        )\n",
    "        cam1_undistort = []\n",
    "        cam2_undistort = []\n",
    "\n",
    "        for camnum, (cam, camfiles1, rot1) in enumerate(zip(cam_names, filenames, rotategrid)):\n",
    "            for fname in camfiles1:\n",
    "                _, filename = os.path.split(fname)\n",
    "                img1 = cv2.imread(fname)\n",
    "                gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "                h, w = img1.shape[:2]\n",
    "                _, corners1 = cv2.findChessboardCorners(gray1, (cbcol, cbrow),  cv2.CALIB_CB_ADAPTIVE_THRESH + \\\n",
    "            cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "                \n",
    "                if rot1:\n",
    "                    corners1 = corners1.reshape((cbrow,cbcol, -1))\n",
    "                    corners1 = corners1.transpose((1, 0, 2))\n",
    "                    corners1 = corners1.reshape((cbrow*cbcol, 1, -1))\n",
    "\n",
    "                corners_origin1 = cv2.cornerSubPix(\n",
    "                    gray1, corners1, (11, 11), (-1, -1), criteria\n",
    "                )\n",
    "                \n",
    "\n",
    "                # Remapping dataFrame_camera1_undistort\n",
    "                im_remapped1 = cv2.remap(gray1, map1_x, map1_y, cv2.INTER_LANCZOS4)\n",
    "                imgpoints_proj_undistort = cv2.undistortPoints(\n",
    "                    src=corners_origin1,\n",
    "                    cameraMatrix=stereo_params[pair[0] + \"-\" + pair[1]][\n",
    "                        \"cameraMatrix{}\".format(camnum+1)\n",
    "                    ],\n",
    "                    distCoeffs=stereo_params[pair[0] + \"-\" + pair[1]][\"distCoeffs{}\".format(camnum+1)],\n",
    "                    P=stereo_params[pair[0] + \"-\" + pair[1]][\"P{}\".format(camnum+1)],\n",
    "                    R=stereo_params[pair[0] + \"-\" + pair[1]][\"R{}\".format(camnum+1)],\n",
    "                )\n",
    "                cam1_undistort.append(imgpoints_proj_undistort)\n",
    "                cv2.imwrite(\n",
    "                    os.path.join(str(path_undistort), filename + \"_undistort.jpg\"),\n",
    "                    im_remapped1,\n",
    "                )\n",
    "                imgpoints_proj_undistort = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        cam1_undistort = np.array(cam1_undistort)\n",
    "        cam2_undistort = np.array(cam2_undistort)\n",
    "        print(\"All images are undistorted and stored in %s\" % str(path_undistort))\n",
    "        print(\n",
    "            \"Use the function ``triangulate`` to undistort the dataframes and compute the triangulation\"\n",
    "        )\n",
    "\n",
    "        if plot == True:\n",
    "            f1, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "            f1.suptitle(\n",
    "                str(\"Original Image: Views from \" + pair[0] + \" and \" + pair[1]),\n",
    "                fontsize=25,\n",
    "            )\n",
    "\n",
    "            # Display images in RGB\n",
    "            ax1.imshow(cv2.cvtColor(img1, cv2.COLOR_BGR2RGB))\n",
    "            ax2.imshow(cv2.cvtColor(img2, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "            norm = mcolors.Normalize(vmin=0.0, vmax=cam1_undistort.shape[1])\n",
    "            plt.savefig(os.path.join(str(path_undistort), \"Original_Image.png\"))\n",
    "\n",
    "            # Plot the undistorted corner points\n",
    "            f2, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "            f2.suptitle(\n",
    "                \"Undistorted corner points on camera-1 and camera-2\", fontsize=25\n",
    "            )\n",
    "            ax1.imshow(cv2.cvtColor(im_remapped1, cv2.COLOR_BGR2RGB))\n",
    "            ax2.imshow(cv2.cvtColor(im_remapped2, cv2.COLOR_BGR2RGB))\n",
    "            for i in range(0, cam1_undistort.shape[1]):\n",
    "                ax1.scatter(\n",
    "                    [cam1_undistort[-1][i, 0, 0]],\n",
    "                    [cam1_undistort[-1][i, 0, 1]],\n",
    "                    marker=markerType,\n",
    "                    s=markerSize,\n",
    "                    color=markerColor,\n",
    "                    alpha=alphaValue,\n",
    "                )\n",
    "                ax2.scatter(\n",
    "                    [cam2_undistort[-1][i, 0, 0]],\n",
    "                    [cam2_undistort[-1][i, 0, 1]],\n",
    "                    marker=markerType,\n",
    "                    s=markerSize,\n",
    "                    color=markerColor,\n",
    "                    alpha=alphaValue,\n",
    "                )\n",
    "            plt.savefig(os.path.join(str(path_undistort), \"undistorted_points.png\"))\n",
    "\n",
    "            # Triangulate\n",
    "            triangulate = auxiliaryfunctions_3d.compute_triangulation_calibration_images(\n",
    "                stereo_params[pair[0] + \"-\" + pair[1]],\n",
    "                cam1_undistort,\n",
    "                cam2_undistort,\n",
    "                path_undistort,\n",
    "                cfg_3d,\n",
    "                plot=True,\n",
    "            )\n",
    "            auxiliaryfunctions.write_pickle(\"triangulate.pickle\", triangulate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triangulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of pairs: [['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211013_ms03_trial06_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211013_ms03_trial06_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial01_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial02_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial02_lateral.mp4']]\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\20211013_ms03_trial06_rear.mp4 using config_file_rear\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211013_ms03_trial06_rear\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\20211013_ms03_trial06_lateral.mp4 using config_file_lateral\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211013_ms03_trial06_lateral\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\20211028_ms03_trial01_rear.mp4 using config_file_rear\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211028_ms03_trial01_rear\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\20211028_ms03_trial01_lateral.mp4 using config_file_lateral\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211028_ms03_trial01_lateral\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\20211028_ms03_trial02_rear.mp4 using config_file_rear\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211028_ms03_trial02_rear\n",
      "This file is already analyzed!\n",
      "Analyzing video D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\20211028_ms03_trial02_lateral.mp4 using config_file_lateral\n",
      "Already analyzed...Checking the meta data for any change in the camera matrices and/or scorer names 20211028_ms03_trial02_lateral\n",
      "This file is already analyzed!\n",
      "All videos were analyzed...\n",
      "Now you can create 3D video(s) using deeplabcut.create_labeled_video_3d\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.triangulate(config_path_3d, r'D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos',\n",
    "                    videotype='.mp4', save_as_csv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "[['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211013_ms03_trial06_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211013_ms03_trial06_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211013_ms03_trial06_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial01_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial01_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial01_lateral.mp4'], ['D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial02_DLC_3D.h5', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial02_rear.mp4', 'D:\\\\UpAndDown\\\\UpAndDown-Ming-2022-02-22-3d\\\\videos\\\\20211028_ms03_trial02_lateral.mp4']]\n",
      "Creating 3D video from 20211013_ms03_trial06_rear.mp4 and 20211013_ms03_trial06_lateral.mp4 using 20211013_ms03_trial06_DLC_3D.h5\n",
      "Looking for filtered predictions...\n",
      "Found the following filtered data:  D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\*20211013_ms03_trial06_rearDLC_resnet50_UpAndDownRearNov27shuffle1_1030000*filtered.h5 D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\*20211013_ms03_trial06_lateralDLC_resnet50_UpAndDownLateral2Feb7shuffle1_1030000*filtered.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:21<00:00,  2.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 3D video from 20211028_ms03_trial01_rear.mp4 and 20211028_ms03_trial01_lateral.mp4 using 20211028_ms03_trial01_DLC_3D.h5\n",
      "Looking for filtered predictions...\n",
      "Found the following filtered data:  D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\*20211028_ms03_trial01_rearDLC_resnet50_UpAndDownRearNov27shuffle1_1030000*filtered.h5 D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\*20211028_ms03_trial01_lateralDLC_resnet50_UpAndDownLateral2Feb7shuffle1_1030000*filtered.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:16<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating 3D video from 20211028_ms03_trial02_rear.mp4 and 20211028_ms03_trial02_lateral.mp4 using 20211028_ms03_trial02_DLC_3D.h5\n",
      "Looking for filtered predictions...\n",
      "Found the following filtered data:  D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\*20211028_ms03_trial02_rearDLC_resnet50_UpAndDownRearNov27shuffle1_1030000*filtered.h5 D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos\\*20211028_ms03_trial02_lateralDLC_resnet50_UpAndDownLateral2Feb7shuffle1_1030000*filtered.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:17<00:00,  1.97s/it]\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.create_labeled_video_3d(config_path_3d, [r'D:\\UpAndDown\\UpAndDown-Ming-2022-02-22-3d\\videos'],\n",
    "                 videotype='.mp4',\n",
    "                 start=100, end=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dca058eb1ebf30ab57a39187fbfe16636a4c81cb6f075563dd9fed9b0e065d2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
